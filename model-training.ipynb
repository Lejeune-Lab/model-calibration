{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIC Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the BIC (Buckling Instability Classification) dataset through the following link:\n",
    "\n",
    "[BIC Dataset](https://open.bu.edu/handle/2144/40085)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to download the dataset and unzip into the right folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-02 15:28:37 URL:https://open.bu.edu/bitstream/handle/2144/40085/BIC1.zip [284717/284717] -> \"BIC1.zip\" [1]\n",
      "2022-12-02 15:28:40 URL:https://open.bu.edu/bitstream/handle/2144/40085/BIC2.zip [589262/589262] -> \"BIC2.zip\" [1]\n",
      "2022-12-02 15:28:44 URL:https://open.bu.edu/bitstream/handle/2144/40085/BIC3.zip [2808306/2808306] -> \"BIC3.zip\" [1]\n"
     ]
    }
   ],
   "source": [
    "!wget --no-verbose https://open.bu.edu/bitstream/handle/2144/40085/BIC1.zip\n",
    "!unzip -qq BIC1.zip 'BIC1/*' -d data/\n",
    "!rm BIC1.zip\n",
    "\n",
    "!wget --no-verbose https://open.bu.edu/bitstream/handle/2144/40085/BIC2.zip\n",
    "!unzip -qq BIC2.zip 'BIC2/*' -d data/\n",
    "!rm BIC2.zip\n",
    "\n",
    "!wget --no-verbose https://open.bu.edu/bitstream/handle/2144/40085/BIC3.zip\n",
    "!unzip -qq BIC3.zip 'BIC3/*' -d data/\n",
    "!rm BIC3.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running each cell, predicted probability vectors for the test set (and calibration set for Neural Network only) will be save in the `results` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gaussian Process Classifier (GPC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of training set sizes used for training the model:\n",
    "tr_sizes = [200, 500, 1000, 2000, 5000, 10000]\n",
    "\n",
    "# Dataset versions:\n",
    "datasets = [1, 2, 3]\n",
    "\n",
    "for d_num in datasets:\n",
    "    p = pathlib.Path(f'results/BIC{d_num}/GPC/')\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    tr_set_input = np.loadtxt(f'data/BIC{d_num}/train_input_data.txt')\n",
    "    tr_set_output = np.loadtxt(f'data/BIC{d_num}/train_output_data.txt')\n",
    "    \n",
    "    test_input = np.loadtxt(f'data/BIC{d_num}/test_input_data.txt')\n",
    "    test_output = np.loadtxt(f'data/BIC{d_num}/test_output_data.txt')\n",
    "    \n",
    "    for tr_size in tr_sizes:\n",
    "        train_input = tr_set_input[0:tr_size]\n",
    "        train_output = tr_set_output[0:tr_size]\n",
    "\n",
    "        kernel = 0.5 * RBF(1.0)\n",
    "        gpc_model = GaussianProcessClassifier(kernel)\n",
    "        gpc_model.fit(train_input, train_output)\n",
    "\n",
    "        probs = gpc_model.predict_proba(test_input)\n",
    "\n",
    "        np.save(f'results/BIC{d_num}/GPC/probs-tr_size-{tr_size}.npy', probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support Vector Classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of training set sizes used for training the model:\n",
    "tr_sizes = [200, 500, 1000, 2000, 5000, 10000]\n",
    "\n",
    "# Dataset versions:\n",
    "datasets = [1, 2, 3]\n",
    "\n",
    "for d_num in datasets:\n",
    "    p = pathlib.Path(f'results/BIC{d_num}/SVC/')\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    tr_set_input = np.loadtxt(f'data/BIC{d_num}/train_input_data.txt')\n",
    "    tr_set_output = np.loadtxt(f'data/BIC{d_num}/train_output_data.txt')\n",
    "    \n",
    "    test_input = np.loadtxt(f'data/BIC{d_num}/test_input_data.txt')\n",
    "    test_output = np.loadtxt(f'data/BIC{d_num}/test_output_data.txt')\n",
    "    \n",
    "    for tr_size in tr_sizes:\n",
    "        train_input = tr_set_input[0:tr_size]\n",
    "        train_output = tr_set_output[0:tr_size]\n",
    "\n",
    "        svc_model = svm.SVC(probability=True, random_state=42)\n",
    "        svc_model.fit(train_input, train_output)\n",
    "\n",
    "        probs = svc_model.predict_proba(test_input)\n",
    "\n",
    "        np.save(f'results/BIC{d_num}/SVC/probs-tr_size-{tr_size}.npy', probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(16, 200),\n",
    "            nn.BatchNorm1d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 200),\n",
    "            nn.BatchNorm1d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(200, 200),\n",
    "            nn.BatchNorm1d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(200, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# A list of training set sizes used for training the model:\n",
    "tr_sizes = [200]#, 500, 1000, 2000, 5000, 10000]\n",
    "\n",
    "# Dataset versions:\n",
    "datasets = [1, 2, 3]\n",
    "\n",
    "for d_num in datasets:\n",
    "    p = pathlib.Path(f'results/BIC{d_num}/NN')\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    tr_set_input = np.loadtxt(f'data/BIC{d_num}/train_input_data.txt')\n",
    "    tr_set_output = np.loadtxt(f'data/BIC{d_num}/train_output_data.txt')\n",
    "    \n",
    "    for tr_size in tr_sizes:\n",
    "        train_input = tr_set_input[0:tr_size]\n",
    "        train_output = tr_set_output[0:tr_size]\n",
    "\n",
    "        cal_input = tr_set_input[10000:11000]\n",
    "        cal_output = tr_set_output[10000:11000]\n",
    "\n",
    "        val_input = tr_set_input[20000:21000]\n",
    "        val_output = tr_set_output[20000:21000]\n",
    "\n",
    "        test_input = np.loadtxt(f'data/BIC{d_num}/test_input_data.txt')\n",
    "\n",
    "        # Normalize inputs:\n",
    "        mu = np.mean(train_input, axis=0)\n",
    "        std = np.std(train_input, axis=0)\n",
    "\n",
    "        train_input = torch.tensor((train_input - mu) / std).to(torch.float)\n",
    "        cal_input = torch.tensor((cal_input - mu) / std).to(torch.float)\n",
    "        val_input = torch.tensor((val_input - mu) / std).to(torch.float)\n",
    "        test_input = torch.tensor((test_input - mu) / std).to(torch.float)\n",
    "        \n",
    "        # TRAIN THE NEURAL NETWORK\n",
    "        train_output = torch.tensor(train_output).to(torch.long)\n",
    "        train_output = nn.functional.one_hot(train_output).to(torch.float)\n",
    "        cal_output = torch.tensor(cal_output).to(torch.long)\n",
    "        cal_output = nn.functional.one_hot(cal_output).to(torch.float)\n",
    "        val_output = torch.tensor(val_output).to(torch.long)\n",
    "        val_output = nn.functional.one_hot(val_output).to(torch.float)\n",
    "        \n",
    "        training_set = TensorDataset(train_input, train_output)\n",
    "        cal_set = TensorDataset(cal_input, cal_output)\n",
    "        val_set = TensorDataset(val_input, val_output)\n",
    "        \n",
    "        train_dataloader = DataLoader(training_set, batch_size=256, shuffle=True)\n",
    "        cal_dataloader = DataLoader(cal_set, batch_size=1000, shuffle=False)\n",
    "        val_dataloader = DataLoader(val_set, batch_size=1000, shuffle=False)\n",
    "        \n",
    "        for model_num in range(10):\n",
    "            torch.manual_seed(model_num + 42)\n",
    "            mlp = MLP()\n",
    "            mlp.to(dev)\n",
    "            mlp.train()\n",
    "\n",
    "            loss_function = nn.CrossEntropyLoss(reduction='sum')\n",
    "            optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-3, weight_decay=0.0)\n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.5)\n",
    "            \n",
    "            training_error = []\n",
    "            cal_error = []\n",
    "            val_error = []\n",
    "            for epoch in range(0, 50):\n",
    "                mlp.train()\n",
    "                sum_loss = 0.0\n",
    "                for inputs, targets in train_dataloader:\n",
    "                    inputs = inputs.to(dev)\n",
    "                    targets = targets.to(dev)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = mlp(inputs)\n",
    "                    loss = loss_function(outputs, targets)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    sum_loss += loss.item()\n",
    "                training_error.append(sum_loss / tr_size)\n",
    "\n",
    "                mlp.eval()\n",
    "                with torch.no_grad():\n",
    "                    sum_loss_val = 0\n",
    "                    for input, output in val_dataloader:\n",
    "                        loss = loss_function(mlp(input), output)\n",
    "                        sum_loss_val += loss.item()\n",
    "                    val_error.append(sum_loss_val / 1000)    \n",
    "                    sum_loss_cal = 0\n",
    "                    for input, output in cal_dataloader:\n",
    "                        loss = loss_function(mlp(cal_input), cal_output)\n",
    "                        sum_loss_cal += loss.item()\n",
    "                    cal_error.append(sum_loss_cal / 1000)\n",
    "    \n",
    "                scheduler.step()\n",
    "            \n",
    "            #plt.plot(np.log(training_error), 'k')\n",
    "            #plt.plot(np.log(cal_error), 'r')\n",
    "            #plt.plot(np.log(val_error), 'b')\n",
    "            #plt.show()\n",
    "\n",
    "            mlp.eval()\n",
    "            with torch.no_grad():\n",
    "                cal_logits = mlp(cal_input)\n",
    "                probs = torch.softmax(cal_logits, axis=1)\n",
    "            \n",
    "            np.save(f'results/BIC{d_num}/NN/probs-cal-tr_size-{tr_size}-model_num-{model_num}.npy', probs)\n",
    "\n",
    "            mlp.eval()\n",
    "            with torch.no_grad():\n",
    "                test_logits = mlp(test_input)\n",
    "                probs = torch.softmax(test_logits, axis=1)\n",
    "            \n",
    "            np.save(f'results/BIC{d_num}/NN/probs-test-tr_size-{tr_size}-model_num-{model_num}.npy', probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABC Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For details of model training check out [ABC_Dataset](https://github.com/pprachas/ABC_dataset) repository on GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have logits of trained models in this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset versions:\n",
    "datasets = [1, 2, 3]\n",
    "\n",
    "for d_num in datasets:\n",
    "    p = pathlib.Path(f'results/ABC{d_num}/NN')\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    logits_cal = np.load(f'data/ABC{d_num}/logits_val.npy')[:,:1000]\n",
    "    probs_cal = np.exp(logits_cal) / np.sum(np.exp(logits_cal), axis=2, keepdims=True)\n",
    "\n",
    "    logits_test = np.load(f'data/ABC{d_num}/logits_test.npy')\n",
    "    probs_test = np.exp(logits_test) / np.sum(np.exp(logits_test), axis=2, keepdims=True)\n",
    "    \n",
    "    for model_num in range(10):\n",
    "        np.save(f'results/ABC{d_num}/NN/probs-cal-model_num-{model_num}.npy', probs_cal[model_num])\n",
    "        np.save(f'results/ABC{d_num}/NN/probs-test-model_num-{model_num}.npy', probs_test[model_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crack Path Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the Mechanical MNIST Crack Path dataset through the following link:\n",
    "\n",
    "[Crack Path Dataset](https://open.bu.edu/handle/2144/42757)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually download\n",
    "\n",
    "- `mat-dist-train.7z`\n",
    "\n",
    "- `mat-dist-test.7z`\n",
    "\n",
    "- `dmg-train-64x64.7z`\n",
    "\n",
    "- `dmg-test-64x64.7z`\n",
    "\n",
    "and extract them into the `data/` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, run the two cells below to download and process the dataset. This may take approximately 30 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-06 19:32:04 URL:https://open.bu.edu/bitstream/handle/2144/42757/dmg-train-64x64.7z [3817372/3817372] -> \"dmg-train-64x64.7z\" [1]\n",
      "2022-12-06 19:39:28 URL:https://open.bu.edu/bitstream/handle/2144/42757/dmg-test-64x64.7z [639023/639023] -> \"dmg-test-64x64.7z\" [1]\n"
     ]
    }
   ],
   "source": [
    "!wget --no-verbose https://open.bu.edu/bitstream/handle/2144/42757/mat-dist-train.7z\n",
    "!7z x mat-dist-train.7z -o./data/Crack-Path/ > log\n",
    "!rm mat-dist-train.7z\n",
    "\n",
    "!wget --no-verbose https://open.bu.edu/bitstream/handle/2144/42757/mat-dist-test.7z\n",
    "!7z x mat-dist-test.7z -o./data/Crack-Path/ > log\n",
    "!rm mat-dist-test.7z\n",
    "\n",
    "!wget --no-verbose https://open.bu.edu/bitstream/handle/2144/42757/dmg-train-64x64.7z\n",
    "!7z x dmg-train-64x64.7z -o./data/Crack-Path/ > log\n",
    "!rm dmg-train-64x64.7z\n",
    "\n",
    "!wget --no-verbose https://open.bu.edu/bitstream/handle/2144/42757/dmg-test-64x64.7z\n",
    "!7z x dmg-test-64x64.7z -o./data/Crack-Path/ > log\n",
    "!rm dmg-test-64x64.7z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmgs_train = np.zeros((60000, 64, 64))\n",
    "mats_train = np.zeros((60000, 64, 64))\n",
    "for i in range(60000):\n",
    "    dmgs_train[i] = np.loadtxt(f'data/Crack-Path/dmg-train-64x64/dmg{i}.txt')\n",
    "    mats_train[i] = np.loadtxt(f'data/Crack-Path/mat-dist-train/mat{i}.txt')\n",
    "\n",
    "dmgs_test = np.zeros((10000, 64, 64))\n",
    "mats_test = np.zeros((10000, 64, 64))\n",
    "for i in range(10000):\n",
    "    dmgs_test[i] = np.loadtxt(f'data/Crack-Path/dmg-test-64x64/dmg{i}.txt')\n",
    "    mats_test[i] = np.loadtxt(f'data/Crack-Path/mat-dist-test/mat{i}.txt')\n",
    "\n",
    "np.save('data/Crack-Path/mat-train.npy', mats_train)\n",
    "np.save('data/Crack-Path/dmg-train.npy', dmgs_train)\n",
    "np.save('data/Crack-Path/mat-test.npy', mats_test)\n",
    "np.save('data/Crack-Path/dmg-test.npy', dmgs_test)\n",
    "\n",
    "del mats_train, dmgs_train, mats_test, dmgs_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\\* Note that we have the weights of the trained models in this repository so you can use them and skip the training phase. Go to [Testing](#testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define the UNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super(UNet, self).__init__()\n",
    "        # Convolutional Block in Encoder Section at Level i: ei   --   Decoder Section: di\n",
    "        # input: 64x64\n",
    "        self.e01 = nn.Conv2d(in_channels=1, out_channels=c, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn01 = nn.BatchNorm2d(num_features=c)\n",
    "        self.e02 = nn.Conv2d(in_channels=c, out_channels=c, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn02 = nn.BatchNorm2d(num_features=c)\n",
    "        \n",
    "        # input: #32x32\n",
    "        self.e11 = nn.Conv2d(in_channels=c, out_channels=2*c, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn11 = nn.BatchNorm2d(num_features=2*c)\n",
    "        self.e12 = nn.Conv2d(in_channels=2*c, out_channels=2*c, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn12 = nn.BatchNorm2d(num_features=2*c)\n",
    "        \n",
    "        # input: 16x16\n",
    "        self.e21 = nn.Conv2d(in_channels=2*c, out_channels=4*c, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn21 = nn.BatchNorm2d(num_features=4*c)\n",
    "        self.e22 = nn.Conv2d(in_channels=4*c, out_channels=4*c, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn22 = nn.BatchNorm2d(num_features=4*c)\n",
    "        \n",
    "        # input: 8x8\n",
    "        self.e31 = nn.Conv2d(in_channels=4*c, out_channels=8*c, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn31 = nn.BatchNorm2d(num_features=8*c)\n",
    "        self.e32 = nn.Conv2d(in_channels=8*c, out_channels=8*c, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn32 = nn.BatchNorm2d(num_features=8*c)\n",
    "        \n",
    "        # input: 16x16\n",
    "        self.d21 = nn.Conv2d(in_channels=8*c, out_channels=4*c, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn23 = nn.BatchNorm2d(num_features=4*c)\n",
    "        self.d22 = nn.Conv2d(in_channels=4*c, out_channels=4*c, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn24 = nn.BatchNorm2d(num_features=4*c)\n",
    "        \n",
    "        # input: 32x32\n",
    "        self.d11 = nn.Conv2d(in_channels=4*c, out_channels=2*c, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn13 = nn.BatchNorm2d(num_features=2*c)\n",
    "        self.d12 = nn.Conv2d(in_channels=2*c, out_channels=2*c, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn14 = nn.BatchNorm2d(num_features=2*c)\n",
    "        \n",
    "        # input: 64x64\n",
    "        self.d01 = nn.Conv2d(in_channels=2*c, out_channels=c, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn03 = nn.BatchNorm2d(num_features=c)\n",
    "        self.d02 = nn.Conv2d(in_channels=c, out_channels=c, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn04 = nn.BatchNorm2d(num_features=c)\n",
    "        \n",
    "        # Increaseing the resolution of image from a lower level to match the upper level\n",
    "        self.upconv3 = nn.ConvTranspose2d(in_channels=8*c, out_channels=4*c, kernel_size=2, stride=2)\n",
    "        self.upconv2 = nn.ConvTranspose2d(in_channels=4*c, out_channels=2*c, kernel_size=2, stride=2)\n",
    "        self.upconv1 = nn.ConvTranspose2d(in_channels=2*c, out_channels=c, kernel_size=2, stride=2)\n",
    "\n",
    "        # Output\n",
    "        self.out = nn.Conv2d(in_channels=c, out_channels=2, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoder\n",
    "        x0 = self.relu(self.bn02(self.e02(self.relu(self.bn01(self.e01(x))))))\n",
    "        x = self.maxpool(x0)\n",
    "\n",
    "        x1 = self.relu(self.bn12(self.e12(self.relu(self.bn11(self.e11(x))))))\n",
    "        x = self.maxpool(x1)\n",
    "        \n",
    "        x2 = self.relu(self.bn22(self.e22(self.relu(self.bn21(self.e21(x))))))\n",
    "        x = self.maxpool(x2)\n",
    "        \n",
    "        x = self.relu(self.bn32(self.e32(self.relu(self.bn31(self.e31(x))))))\n",
    "        \n",
    "        # decoder\n",
    "        x = torch.cat((self.upconv3(x), x2), dim=1)\n",
    "        x = self.relu(self.bn24(self.d22(self.relu(self.bn23(self.d21(x))))))\n",
    "\n",
    "        x = torch.cat((self.upconv2(x), x1), dim=1)\n",
    "        x = self.relu(self.bn14(self.d12(self.relu(self.bn13(self.d11(x))))))\n",
    "\n",
    "        x = torch.cat((self.upconv1(x), x0), dim=1)\n",
    "        x = self.relu(self.bn04(self.d02(self.relu(self.bn03(self.d01(x))))))\n",
    "\n",
    "        out = self.out(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_step(model, loss_fn, optimizer):\n",
    "    def train_step(x, y):\n",
    "        model.train()\n",
    "\n",
    "        out = model(x)\n",
    "        \n",
    "        loss = loss_fn(out, y)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    return train_step\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    " \n",
    "    def forward(self, inputs, target, smooth=0.5):\n",
    "        gt_onehot = F.one_hot(target.reshape(-1, 64, 64).to(torch.long), 2).permute(0, 3, 1, 2)\n",
    "        inputs = torch.softmax(inputs, axis=1)       \n",
    "        \n",
    "        dice_loss = - (2. * (inputs * gt_onehot).sum() + smooth) / ((inputs + gt_onehot).sum() + smooth)\n",
    "        \n",
    "        return 1 + dice_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_size = 10000\n",
    "val_size = 1000\n",
    "cal_size = 1000\n",
    "\n",
    "tr_input = np.load('data/Crack-Path/mat-train.npy').reshape(-1, 1, 64, 64)\n",
    "tr_output = np.load('data/Crack-Path/dmg-train.npy').reshape(-1, 1, 64, 64)\n",
    "\n",
    "train_input = tr_input[:tr_size]\n",
    "train_output = tr_output[:tr_size]\n",
    "\n",
    "val_input = tr_input[10000:10000+val_size]\n",
    "val_output = tr_output[10000:10000+val_size]\n",
    "\n",
    "cal_input = tr_input[20000:20000+cal_size]\n",
    "cal_output = tr_output[20000:20000+cal_size]\n",
    "\n",
    "del tr_input, tr_output\n",
    "\n",
    "test_input = np.load('data/Crack-Path/mat-test.npy').reshape(-1, 1, 64, 64)\n",
    "test_output = np.load('data/Crack-Path/dmg-test.npy').reshape(-1, 1, 64, 64)\n",
    "\n",
    "mu = np.mean(train_input)\n",
    "std = np.std(train_input)\n",
    "\n",
    "train_input = torch.tensor((train_input-mu)/std, dtype=torch.double)\n",
    "train_output = torch.tensor(train_output, dtype=torch.double)\n",
    "val_input = torch.tensor((val_input-mu)/std, dtype=torch.double)\n",
    "val_output = torch.tensor(val_output, dtype=torch.double)\n",
    "cal_input = torch.tensor((cal_input-mu)/std, dtype=torch.double)\n",
    "cal_output = torch.tensor(cal_output, dtype=torch.double)\n",
    "test_input = torch.tensor((test_input-mu)/std, dtype=torch.double)\n",
    "test_output = torch.tensor(test_output, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, axs = plt.subplots(1, 2)\n",
    "for ax in axs:\n",
    "    ax.axis('off')\n",
    "axs[0].set_title('Material Distribution')\n",
    "axs[1].set_title('Damage Field')\n",
    "input_plot = axs[0].imshow(torch.flip(train_input[5, 0], (0,)))\n",
    "output_plot = axs[1].imshow(torch.flip(train_output[5, 0], (0,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(epochs, learning_rate, decay_rate, decay_step, batch_size, channels, model_name):\n",
    "    p = pathlib.Path(f'results/Crack-Path/best_models/')\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # data\n",
    "    train_loader = DataLoader(TensorDataset(train_input, train_output), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(val_input, val_output), batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # GPU\n",
    "    dev = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    model = UNet(channels)\n",
    "    model.double()\n",
    "    # remove comment if you are using more than one GPU\n",
    "    #model = nn.DataParallel(model, device_ids = [0])\n",
    "    model.to(dev)\n",
    "\n",
    "    min_val_loss = np.inf\n",
    "    \n",
    "    loss_fn = DiceLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)#torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_step, gamma=decay_rate)\n",
    "\n",
    "    train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "    train_loss = [] # recording training error after each epoch\n",
    "    val_loss = [] # recording validation error after each epoch\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0\n",
    "        n_batches = 0\n",
    "        # 1 training epoch\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            n_batches += 1\n",
    "            x_batch = x_batch.to(dev)\n",
    "            y_batch = y_batch.to(dev)\n",
    "            l = train_step(x_batch, y_batch)\n",
    "            if n_batches % 100 == 0:\n",
    "                print(f\"epoch {epoch+1}/{epochs} | batch {n_batches} | batch loss: {l.item()}\")\n",
    "            loss += l * len(x_batch)\n",
    "        scheduler.step()\n",
    "        train_loss = np.append(train_loss, loss.item()/(tr_size))\n",
    "\n",
    "        # Validation error calculation\n",
    "        with torch.no_grad():\n",
    "            loss_val = 0\n",
    "            n_batches_val = 0\n",
    "            for x_batch_val, y_batch_val in val_loader:\n",
    "                n_batches_val += 1\n",
    "                x_batch_val = x_batch_val.to(dev)\n",
    "                y_batch_val = y_batch_val.to(dev)\n",
    "                model.eval()\n",
    "                val_out = model(x_batch_val)\n",
    "                loss_val += loss_fn(val_out, y_batch_val) * len(x_batch_val)\n",
    "\n",
    "        val_loss = np.append(val_loss, loss_val.item()/(val_size))\n",
    "        print('epoch: ', epoch+1, '  |  loss (training): ', loss.item()/(tr_size), '  |  loss (validation): ', loss_val.item()/(val_size), end='\\r')\n",
    "\n",
    "        is_best = False\n",
    "        if min_val_loss > val_loss[-1]:\n",
    "            is_best = True\n",
    "            min_val_loss = val_loss[-1]\n",
    "    \n",
    "        if is_best:\n",
    "            torch.save(model.state_dict(), f'results/Crack-Path/best_models/{model_name}.pt')\n",
    "\n",
    "    print('epoch: ', epoch+1, '  |  loss (training): ', loss.item()/(tr_size), '  |  loss (validation): ', loss_val.item()/(val_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training 10 UNet models on the Crack Path dataset with random initialization.\n",
    "\n",
    "\\* Note that without a GPU this training can take a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(f'Training model {i}')\n",
    "    torch.manual_seed(i)\n",
    "    random.seed(i)\n",
    "    np.random.seed(i)\n",
    "    training(epochs=50, learning_rate=0.0001, decay_rate=1, decay_step=50, batch_size=32, channels=32, model_name=f'unet-{i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "<a id='testing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute and save predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_loader = DataLoader(TensorDataset(cal_input, cal_output), batch_size=10, shuffle=False)\n",
    "test_loader = DataLoader(TensorDataset(test_input, test_output), batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "p = pathlib.Path(f'results/Crack-Path/NN/')\n",
    "p.mkdir(parents=True, exist_ok=True)    \n",
    "\n",
    "for m in range(10):\n",
    "    model = UNet(32)\n",
    "    model.load_state_dict(torch.load(f'unet-{m}.pt'))\n",
    "    model.double()\n",
    "    # remove comment if you are using more than one GPU\n",
    "    #model = nn.DataParallel(model, device_ids = [0])\n",
    "    model.to(dev)\n",
    "    model.eval()\n",
    "\n",
    "    cal_probs = []\n",
    "    with torch.no_grad():\n",
    "        for x, _ in cal_loader:\n",
    "            x = x.to(dev)\n",
    "            probs = torch.softmax(model(x), axis=1)\n",
    "            cal_probs.append(probs.permute(0, 2, 3, 1).flatten(0, -2).cpu().detach().numpy())\n",
    "    cal_probs = np.concatenate(cal_probs, axis=0)\n",
    "    np.save(f'results/Crack-Path/NN/probs-cal-model_num-{m}.npy', cal_probs)\n",
    "    \n",
    "    test_probs = []\n",
    "    with torch.no_grad():\n",
    "        for x, _ in test_loader:\n",
    "            x = x.to(dev)\n",
    "            probs = torch.softmax(model(x), axis=1)\n",
    "            test_probs.append(probs.permute(0, 2, 3, 1).flatten(0, -2).cpu().detach().numpy())\n",
    "    test_probs = np.concatenate(test_probs, axis=0)\n",
    "    np.save(f'results/Crack-Path/NN/probs-test-model_num-{m}.npy', test_probs)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
